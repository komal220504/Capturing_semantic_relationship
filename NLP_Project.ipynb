{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPJQkKF85FnCyJ5zcnFlLj6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/komal220504/Capturing_semantic_relationship/blob/main/NLP_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9yksIkZjgul3"
      },
      "outputs": [],
      "source": [
        "pip install transformers sentence-transformers\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "\n",
        "# Load pre-trained BERT model (optimized for semantic similarity)\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "# Sample sentences\n",
        "sentences = [\n",
        "    \"A dog is barking in the yard.\",\n",
        "    \"There is a dog making noise outside.\",\n",
        "    \"I love eating pizza on weekends.\",\n",
        "    \"A canine is howling in the backyard.\"\n",
        "]\n",
        "\n",
        "# Encode sentences into embeddings\n",
        "embeddings = model.encode(sentences, convert_to_tensor=True)\n",
        "\n",
        "# Compute cosine similarity between all sentence pairs\n",
        "similarity_matrix = util.pytorch_cos_sim(embeddings, embeddings)\n",
        "\n",
        "# Display similarity scores\n",
        "for i in range(len(sentences)):\n",
        "    for j in range(len(sentences)):\n",
        "        print(f\"Similarity between:\\n \\\"{sentences[i]}\\\"\\n and\\n \\\"{sentences[j]}\\\"\\n → {similarity_matrix[i][j]:.4f}\\n\")\n"
      ],
      "metadata": {
        "id": "L0IFX8XQgvsH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install transformers sentence-transformers torch\n"
      ],
      "metadata": {
        "id": "_Cwf_ECCiJwb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import MarianMTModel, MarianTokenizer\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "import torch\n",
        "\n",
        "# Step 1: Load translation model (e.g., French to English)\n",
        "src_lang = \"fr\"  # Source language code\n",
        "model_name = f'Helsinki-NLP/opus-mt-{src_lang}-en'\n",
        "\n",
        "translator_tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
        "translator_model = MarianMTModel.from_pretrained(model_name)\n",
        "\n",
        "def translate_to_english(sentences):\n",
        "    inputs = translator_tokenizer(sentences, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "    translated = translator_model.generate(**inputs)\n",
        "    return [translator_tokenizer.decode(t, skip_special_tokens=True) for t in translated]\n",
        "\n",
        "# Step 2: Load a sentence transformer model (VSM)\n",
        "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "# Step 3: Multilingual documents (in French)\n",
        "documents_fr = [\n",
        "    \"Le chien aboie dans la cour.\",      # The dog barks in the yard.\n",
        "    \"J'aime manger de la pizza.\",        # I love eating pizza.\n",
        "    \"Un chat dort sur le canapé.\",       # A cat is sleeping on the couch.\n",
        "    \"Le soleil brille aujourd'hui.\"      # The sun is shining today.\n",
        "]\n",
        "\n",
        "# Step 4: Translate documents to English for embedding\n",
        "documents_en = translate_to_english(documents_fr)\n",
        "\n",
        "# Step 5: Convert to semantic vectors\n",
        "doc_embeddings = embedding_model.encode(documents_en, convert_to_tensor=True)\n",
        "\n",
        "# Step 6: Query (in English)\n",
        "query = \"A dog is barking outside.\"\n",
        "query_embedding = embedding_model.encode(query, convert_to_tensor=True)\n",
        "\n",
        "# Step 7: Compute cosine similarities\n",
        "cos_scores = util.pytorch_cos_sim(query_embedding, doc_embeddings)[0]\n",
        "\n",
        "# Step 8: Show results\n",
        "print(\"Query:\", query)\n",
        "print(\"\\nTop relevant documents:\")\n",
        "top_results = torch.topk(cos_scores, k=3)\n",
        "\n",
        "for score, idx in zip(top_results[0], top_results[1]):\n",
        "    print(f\"\\nFrench: {documents_fr[idx]}\")\n",
        "    print(f\"English: {documents_en[idx]}\")\n",
        "    print(f\"Score: {score:.4f}\")\n"
      ],
      "metadata": {
        "id": "bf5ladfkiLAN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install transformers sentence-transformers torch\n"
      ],
      "metadata": {
        "id": "wspX-Fo1iTTH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import MarianMTModel, MarianTokenizer\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "import torch\n",
        "\n",
        "# Step 1: Load the Machine Translation model (French to English)\n",
        "source_lang = \"fr\"  # You can change this to 'de', 'es', etc.\n",
        "mt_model_name = f\"Helsinki-NLP/opus-mt-{source_lang}-en\"\n",
        "\n",
        "tokenizer = MarianTokenizer.from_pretrained(mt_model_name)\n",
        "mt_model = MarianMTModel.from_pretrained(mt_model_name)\n",
        "\n",
        "def translate(sentences):\n",
        "    \"\"\"Translate sentences from source_lang to English.\"\"\"\n",
        "    tokens = tokenizer(sentences, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "    translated = mt_model.generate(**tokens)\n",
        "    return [tokenizer.decode(t, skip_special_tokens=True) for t in translated]\n",
        "\n",
        "# Step 2: Load the VSM Model (Sentence Embeddings)\n",
        "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "# Step 3: Example Multilingual Documents (French)\n",
        "documents_fr = [\n",
        "    \"Le chien court dans le jardin.\",         # The dog runs in the garden.\n",
        "    \"Je cuisine une pizza délicieuse.\",       # I am cooking a delicious pizza.\n",
        "    \"Le soleil brille fortement aujourd'hui.\",# The sun is shining brightly today.\n",
        "    \"Un chat dort sur le canapé.\"             # A cat sleeps on the couch.\n",
        "]\n",
        "\n",
        "# Step 4: Translate to English\n",
        "documents_en = translate(documents_fr)\n",
        "\n",
        "# Step 5: Create Vector Representations (VSM)\n",
        "document_embeddings = embedding_model.encode(documents_en, convert_to_tensor=True)\n",
        "\n",
        "# Step 6: Query (in English or Translated)\n",
        "query = \"The dog is playing in the yard.\"\n",
        "query_embedding = embedding_model.encode(query, convert_to_tensor=True)\n",
        "\n",
        "# Step 7: Compute Similarities\n",
        "cosine_scores = util.pytorch_cos_sim(query_embedding, document_embeddings)[0]\n",
        "\n",
        "# Step 8: Display top matches\n",
        "top_results = torch.topk(cosine_scores, k=3)\n",
        "\n",
        "print(\"\\n Query:\", query)\n",
        "print(\"\\nTop Matching Documents:\")\n",
        "for score, idx in zip(top_results[0], top_results[1]):\n",
        "    print(f\"\\n→ French: {documents_fr[idx]}\")\n",
        "    print(f\"→ English: {documents_en[idx]}\")\n",
        "    print(f\"→ Similarity Score: {score.item():.4f}\")\n"
      ],
      "metadata": {
        "id": "d4HJiFkrjS4f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GR1FVRi9jX-F"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}